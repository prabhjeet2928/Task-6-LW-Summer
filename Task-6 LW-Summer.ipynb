{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98b1878",
   "metadata": {},
   "source": [
    "# Task 06 👨🏻‍💻\n",
    "\n",
    "## Team Task\n",
    "\n",
    "### Task Description 📄\n",
    "\n",
    "❄️ Create a program that perform below mentioned task upon recognizing a particular face. \n",
    "\n",
    "📌 When it recognize your face, then -\n",
    "👉 Create EC2 instance in the AWS using CLI. \n",
    "👉 Create 5 GB EBS volume and attach it to the instance.\n",
    "\n",
    "📌 When it recognize second face, it can be your friend or family members face. \n",
    "👉 It send mail to your mail id by writing this is face of your_name.\n",
    "\n",
    "📌 When it recognize third face, it can be your friend or family members face.\n",
    "👉 It send whatsapp message to your friend, it can be anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d68fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyttsx3 as sp\n",
    "import task6_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed5c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6\n",
      "\n",
      "Team Task\n",
      "\n",
      "Task Description\n",
      "\n",
      "Create a program that perform below mentioned task upon recognizing a particular face. \n",
      "\n",
      "1. \n",
      "When it recognize your face, then -\n",
      "    Create EC2 instance in the AWS using CLI. \n",
      "    Create 5 GB EBS volume and attach it to the instance.\n",
      "    \n",
      "2. \n",
      "When it recognize second face, in my case I using lalita's face, then - \n",
      "    It send mail to your mail id by writing this is face of your_name.\n",
      "3. \n",
      "When it recognize third face, in my case I using shivkumar's face, then -\n",
      "    It send whatsapp message to your friend, it can be anything.\n"
     ]
    }
   ],
   "source": [
    "task6_voice.introduction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e312d54",
   "metadata": {},
   "source": [
    "# Step-1 -> Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39994929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    \n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d7f4b",
   "metadata": {},
   "source": [
    "# Step-2 -> Capture the user's images for creating a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11da8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_capture(user):\n",
    "\n",
    "    # Initialize Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    \n",
    "    #Create faces folder to put dataset\n",
    "    os.system('mkdir .\\\\faces')\n",
    "    #Create folder with user's name\n",
    "    os.system('mkdir .\\\\faces\\{}'.format(user))\n",
    "\n",
    "    # Collect 100 samples of your face from webcam input\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200)) #resize to (200, 200)\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save file in specified directory with unique name\n",
    "            file_name_path = './faces/{}/'.format(user) + str(count) + '.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Cropper', face)\n",
    "\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    sp.speak(\"Collecting {} Samples Complete\".format(user))\n",
    "    print(\"Collecting {} Samples Complete\".format(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5d7b4",
   "metadata": {},
   "source": [
    "# Step-3 -> Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72490c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-contrib-python\n",
    "def train_model(users):\n",
    "    \n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    for c in range(len(users)):\n",
    "        \n",
    "        # Get the training data we previously made\n",
    "        data_path = './faces/{}/'.format(users[c])\n",
    "        onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "        # Create arrays for training data and labels\n",
    "        Training_Data, Labels = [], []\n",
    "\n",
    "        # Open training images in our datapath\n",
    "        # Create a numpy array for training data\n",
    "        for i, files in enumerate(onlyfiles):\n",
    "            image_path = data_path + onlyfiles[i]\n",
    "            images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "            Labels.append(i)\n",
    "\n",
    "        # Create a numpy array for both training data and labels\n",
    "        Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "        # Initialize facial recognizer\n",
    "        # model = cv2.face.createLBPHFaceRecognizer()\n",
    "        # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "        # pip install opencv-contrib-python\n",
    "        # model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "        models.append(cv2.face_LBPHFaceRecognizer.create())\n",
    "        # Let's train our model \n",
    "        models[c].train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "        sp.speak(\"{} images model trained successfully\".format(users[c]))\n",
    "        print(\"{} images model trained successfully\".format(users[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b882bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of users:- 3\n",
      "Enter user's name:- prabhjeet\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting prabhjeet Samples Complete\n",
      "prabhjeet's hundred images has been captured\n",
      "Enter user's name:- lalita\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting lalita Samples Complete\n",
      "lalita's hundred images has been captured\n",
      "Enter user's name:- shivkumar\n",
      "Collecting shivkumar Samples Complete\n",
      "shivkumar's hundred images has been captured\n",
      "prabhjeet images model trained successfully\n",
      "lalita images model trained successfully\n",
      "shivkumar images model trained successfully\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "models = []\n",
    "sp.speak(\"Enter the number of users\")\n",
    "no_users = int(input(\"Enter the number of users:- \"))\n",
    "sp.speak(no_users)\n",
    "for i in range(no_users):\n",
    "    sp.speak(\"Enter user's name\")\n",
    "    user =  input(\"Enter user's name:- \")\n",
    "    sp.speak(user)\n",
    "    users.append(user)\n",
    "    user_capture(user)\n",
    "    sp.speak(\"{}'s hundred images has been captured\".format(user))\n",
    "    print(\"{}'s hundred images has been captured\".format(user))\n",
    "train_model(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7b0c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prabhjeet', 'lalita', 'shivkumar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3632fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See the multi-users name\n"
     ]
    }
   ],
   "source": [
    "task6_voice.users()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6269f1",
   "metadata": {},
   "source": [
    "# Step-4 -> Create a Function for Sending Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811f0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.message import EmailMessage\n",
    "import smtplib\n",
    "import getpass\n",
    "import pyttsx3 as sp\n",
    "\n",
    "def mail(to,user,acc_name):\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(\"Face Detected of {} has been successfully\".format(acc_name))\n",
    "    msg['Subject'] = \"Face Detection\"\n",
    "    msg['To'] = to\n",
    "    msg['From'] = user\n",
    "    sp.speak('Enter your password')\n",
    "    password = getpass.getpass(prompt='Enter password: ')\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\",587)\n",
    "    server.starttls()\n",
    "    server.login(user,password)\n",
    "    server.send_message(msg)\n",
    "    sp.speak('mail sent successfully')\n",
    "    print('Mail sent Successfully')\n",
    "    server.quit()\n",
    "\n",
    "\n",
    "def send_mail() :\n",
    "    sp.speak(\"Enter Your Profile Name\")\n",
    "    name = input(\"Enter Your Profile Name: \")\n",
    "    sp.speak(\"enter sender email\")\n",
    "    user =input(\"Enter Sender Email: \")\n",
    "    #print(\"Enter Receiver Email :\",end=\"\")\n",
    "    sp.speak(\"Enter Receiver email\")\n",
    "    rem=input(\"Enter Receiver email: \")\n",
    "    print(\"Sending Email ....\")\n",
    "    sp.speak(\"sending email\")\n",
    "    mail(rem,user,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107735d9",
   "metadata": {},
   "source": [
    "# Step-5 -> Create a Function for Launching EC2 Instance, Create EBS Volume and Attach to Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5035f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def aws_instance():\n",
    "    sp.speak(\"Enter count\")\n",
    "    count = int(input(\"Enter count: \"))\n",
    "    sp.speak(\"Enter Key Name\")\n",
    "    key_name = input(\"Enter Key Name: \")\n",
    "    sp.speak(\"Enter Avaliability Zone\")\n",
    "    az = input(\"Enter Avaliability Zone: \")\n",
    "    sp.speak(\"Enter Disk Size\")\n",
    "    size = input(\"Enter Disk Size: \")\n",
    "    os.system(\"aws ec2 run-instances --image-id ami-0ad704c126371a549  --instance-type t2.micro  --count {}  --subnet-id subnet-a8626bc0 --security-group-ids sg-2e35e649 --key-name {}\".format(count,key_name))\n",
    "    time.sleep(20)\n",
    "    os.system(\"msedge -guest https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Instances:instanceState=running\")\n",
    "    sp.speak(\"Instance launch Successfully\")\n",
    "    print(\"Instance launch Successfully\")\n",
    "    InstanceId = os.popen('''aws ec2 describe-instances --filters Name=instance-state-name,Values=running  --query \"Reservations[].Instances[].{Instance:InstanceId}\" --output text''').read()\n",
    "    #aws ec2 create-tags --resources i-045c826aae984ee6c --tags Key=Name,Value=MyInstance\n",
    "    os.system(\"aws ec2 create-volume --availability-zone {} --volume-type gp2 --size {}\".format(az,size))\n",
    "    time.sleep(20)\n",
    "    os.system(\"msedge -guest https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Volumes:sort=desc:createTime\")\n",
    "    sp.speak(\"Volume created Successfully\")\n",
    "    print(\"Volume created Successfully\")\n",
    "    VolumeId = os.popen('''aws ec2 describe-volumes --filters Name=status,Values=available Name=size,Values={} --query \"Volumes[*].VolumeId\" --output text'''.format(count)).read()\n",
    "    os.system(\"aws ec2 attach-volume  --volume-id \" + VolumeId[:-1] + \" --instance-id \" + InstanceId[:-1] + \" --device /dev/sdf\")\n",
    "    time.sleep(20)\n",
    "    os.system(\"msedge -guest https://ap-south-1.console.aws.amazon.com/ec2/v2/home?region=ap-south-1#Volumes:sort=desc:createTime\")\n",
    "    sp.speak(\"Volume attached successfully\")\n",
    "    print(\"Volume attached successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f6a68",
   "metadata": {},
   "source": [
    "# Step-6 -> Create a Function for Sending Whatsapp Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1003f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pyttsx3 as sp\n",
    "import time\n",
    "\n",
    "def whatsapp_message():\n",
    "            sp.speak(\"welcome to whatsapp\")\n",
    "            sp.speak(\"login to your account\")\n",
    "            print(\"opening whatsapp\")\n",
    "            sp.speak(\"opening whatsapp\")\n",
    "            browser = webdriver.Edge(executable_path='D:\\\\edge_webdriver\\\\msedgedriver.exe')\n",
    "            browser.get('https://web.whatsapp.com')\n",
    "            time.sleep(10)\n",
    "            sp.speak(\"Enter your Friend or Group Name: \")\n",
    "            friend = input('Enter your friend/group name: ')\n",
    "            searchbox = browser.find_element_by_xpath('//*[@id=\"side\"]/div[1]/div/label/div/div[2]')\n",
    "            searchbox.send_keys(friend)\n",
    "            searchbox.send_keys(Keys.ENTER)\n",
    "                    \n",
    "            message = \"Hii {}...........    My Current Face has been detected successfully.....\".format(friend)\n",
    "            print(\"sending message to {}....\".format(friend))\n",
    "            sp.speak(\"sending message to {}......\".format(friend))\n",
    "            messagebox = browser.find_element_by_xpath('//*[@id=\"main\"]/footer/div[1]/div[2]/div/div[2]')\n",
    "            messagebox.send_keys(message)\n",
    "            messagebox.send_keys(Keys.ENTER)\n",
    "            print(\"Message: {}\".format(message))\n",
    "            sp.speak(\"Message is {}\".format(message))\n",
    "            print(\"message to {} has sent sucessfully\".format(friend))\n",
    "            sp.speak(\"message to {} has sent sucessfully\".format(friend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dd432",
   "metadata": {},
   "source": [
    "# Step-7 -> Run Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a8b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) == 0:\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "def get_confidence_score(results):\n",
    "    if results[1] < 500:\n",
    "        confidence = int( 100 * (1 - (results[1])/400) )\n",
    "    return confidence\n",
    "\n",
    "\n",
    "def face_recog():\n",
    "    # Open Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        image, face = face_detector(frame)\n",
    "\n",
    "        try:\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Pass face to prediction model\n",
    "            # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "            results = []\n",
    "            confidences = []\n",
    "            c = 0\n",
    "\n",
    "            for c in range(len(users)):\n",
    "                results.append(models[c].predict(face))\n",
    "\n",
    "            for c in range(len(users)):\n",
    "                confidences.append(get_confidence_score(results[c]))\n",
    "\n",
    "            pred_user  = None\n",
    "\n",
    "            largest = max(confidences)\n",
    "            conf_ind = confidences.index(largest)\n",
    "            confidence = confidences[conf_ind]\n",
    "            pred_user = users[conf_ind]\n",
    "\n",
    "            display_string = str(confidence) + '% Confident it is ' + pred_user\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (144,238,144), 2)\n",
    "\n",
    "\n",
    "            if confidence >= 90:\n",
    "                cv2.putText(image, \"Hi!! \"+ pred_user, (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image)\n",
    "                if pred_user == users[len(users) - 3]:\n",
    "                    #cv2.imwrite(\"{}.jpg\".format(pred_user), image)\n",
    "                    cv2.imshow('Face Recognition',image)\n",
    "                    cv2.waitKey(2)\n",
    "                    aws_instance()\n",
    "                    break\n",
    "                elif pred_user == users[len(users) - 2]:\n",
    "                    #cv2.imwrite(\"{}.jpg\".format(pred_user), image)\n",
    "                    cv2.imshow('Face Recognition',image)\n",
    "                    cv2.waitKey(2)\n",
    "                    send_mail()\n",
    "                    break\n",
    "                if pred_user == users[len(users) - 1]:\n",
    "                    #cv2.imwrite(\"{}.jpg\".format(pred_user), image)\n",
    "                    cv2.imshow('Face Recognition',image)\n",
    "                    cv2.waitKey(2)\n",
    "                    whatsapp_message()\n",
    "                    break\n",
    "                else:\n",
    "                    cv2.putText(image, \"Not Registered User....\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                    cv2.imshow('Face Recognition', image)\n",
    "                    cv2.waitKey(2)\n",
    "                    break\n",
    "                break\n",
    "            else:   \n",
    "                #cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "        except:\n",
    "            cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            pass\n",
    "        if cv2.waitKey(1) == 27: #27 is the Esc Key\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9e40e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we will call the function as per given above when I give 'prabhjeet' face, it call the aws_instance() function.\n",
      "\n",
      "In this aws_instance() function When 'prabhjeet' face comes up 90% or above accuracy then, it launch the ec2 instance for amazon linux, create an extra volume and attach to that new instance as well by input the count, availability zone, key name and disk size.\n"
     ]
    }
   ],
   "source": [
    "task6_voice.final_touch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00d99ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter count: 1\n",
      "Enter Key Name: mumbai_os\n",
      "Enter Avaliability Zone: ap-south-1a\n",
      "Enter Disk Size: 1\n",
      "Instance launch Successfully\n",
      "Volume created Successfully\n",
      "Volume attached successfully\n"
     ]
    }
   ],
   "source": [
    "face_recog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4391fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Again, we will call the function as per given above when I give 'lalita' face, it call the send_mail() function.\n",
      "\n",
      "In send_mail() function when 'lalita' face comes up with 90% or above accuracy then, it send the email through SMTP Protocol by giving an some input of profile name, sender email, receiver email and sender password.\n"
     ]
    }
   ],
   "source": [
    "task6_voice.final_touch2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58749244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Again, we will call the function as per given above when I give 'shivkumar' face, it call the whatsapp_message() function.\n",
      "    \n",
      "In this whatsapp_message() function when 'shivkumar'face comes up with 90% or above accuracy then, It use to send the default static message for face detection by inputting your contact name and it also opens the new tab for opening the whatsapp through its microsoft edge webdriver and able to send message by using selenium  module in python.\n"
     ]
    }
   ],
   "source": [
    "task6_voice.final_touch3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5933cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening whatsapp\n",
      "Enter your friend/group name: pietshivkumar singh\n",
      "sending message to pietshivkumar singh....\n",
      "Message: Hii pietshivkumar singh...........    My Current Face has been detected successfully.....\n",
      "message to pietshivkumar singh has sent sucessfully\n"
     ]
    }
   ],
   "source": [
    "face_recog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0932c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THANK YOU FOR WATCHING THIS VIDEO\n"
     ]
    }
   ],
   "source": [
    "task6_voice.thank_you()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041e93c",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
